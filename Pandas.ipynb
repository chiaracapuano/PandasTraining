{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Pandas.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-4gr26tJFbg6"
   },
   "source": [
    "# Pandas and Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nG1qwwpVFbg8"
   },
   "source": [
    "It's important that you hone your Pandas and exploratory data analysis (EDA) skills before the session starts. If you are having trouble, Google is your best friend! If you are still having problems, ask your fellow Fellows for help through the Platform. Good luck!\n",
    "<br> <br>\n",
    "Begin by downloading the Crunchbase dataset on start-up investments, which can be found [here](https://drive.google.com/file/d/1zsjN1tGWdXPb4wf4eTM62usMciSV-0sX/view)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GwK-b_KMFbg9"
   },
   "source": [
    "**Exercise:**\n",
    "The first thing we should do is import the Pandas library. It will probably be helpful to give this library an alias, too. Then, import the dataset and give it a name!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "1mXvrnK2Fbg_",
    "scrolled": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 494
    },
    "outputId": "fde579a2-ac5c-4ce8-9b1d-2ee8248d0158"
   },
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./Crunchbase_Startup_Investment_Data.csv\")"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xf3 in position 7: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnicodeDecodeError\u001B[0m                        Traceback (most recent call last)",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._string_convert\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers._string_box_utf8\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mUnicodeDecodeError\u001B[0m: 'utf-8' codec can't decode byte 0xf3 in position 7: invalid continuation byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mUnicodeDecodeError\u001B[0m                        Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-6-3fb31beb5ac0>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"./Crunchbase_Startup_Investment_Data.csv\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/PandasTraining/venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001B[0m\n\u001B[1;32m    684\u001B[0m     )\n\u001B[1;32m    685\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 686\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    687\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    688\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/PandasTraining/venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    456\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    457\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 458\u001B[0;31m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mparser\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnrows\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    459\u001B[0m     \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    460\u001B[0m         \u001B[0mparser\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/PandasTraining/venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36mread\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m   1184\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnrows\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1185\u001B[0m         \u001B[0mnrows\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_validate_integer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"nrows\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnrows\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1186\u001B[0;31m         \u001B[0mret\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnrows\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1187\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1188\u001B[0m         \u001B[0;31m# May alter columns / col_dict\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/PandasTraining/venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36mread\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m   2143\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnrows\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2144\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2145\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reader\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnrows\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2146\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mStopIteration\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2147\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_first_chunk\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader.read\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._read_rows\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._string_convert\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers._string_box_utf8\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mUnicodeDecodeError\u001B[0m: 'utf-8' codec can't decode byte 0xf3 in position 7: invalid continuation byte"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6TFhcHVVFbhI"
   },
   "source": [
    "Some of you may have experienced a problem already - thats ok! We can deal.\n",
    "<br><br>\n",
    "The problem here is that the dataset is encoded in Latin-1, but Pandas has defaulted to UTF-8 encoding. Bad, pandas! But it's ok, you can correct for this by specifying the encoding in your command. <br><br>\n",
    "*Pro tip:* If you're having trouble, try Googling your error messages. You are probably not the first to encounter any particular error."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "kXmLvm0gFbhJ",
    "colab": {}
   },
   "source": [
    "df = pd.read_csv(\"./Crunchbase_Startup_Investment_Data.csv\", encoding='latin1')\n",
    "\n"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cAh6GX0DFbhM"
   },
   "source": [
    "Now that we have successfully imported the data, let's do some Exploratory Data Analysis! \n",
    "\n",
    "**Exercise:**<br>\n",
    "Let's begin by displaying the first 5 rows of each column. <br>(*Hint: there is a special command for this!*)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "1NyRT2qCFbhO",
    "colab": {}
   },
   "source": [
    "print(df.head())\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8CzgyRDxFbhT"
   },
   "source": [
    "**Question:**<br>\n",
    "How many columns are in this dataset? How many rows?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "laPNW9a5FbhU",
    "colab": {}
   },
   "source": [
    "print(\"N of rows\", len(df))\n",
    "print(\"N of columns\", len(df.columns))\n",
    "print(df.info())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WZSTCh8WFbhZ"
   },
   "source": [
    "**Exercise:**<br>\n",
    "You'll probably notice that the command above actually truncates the number of columns it shows. This is to make display\n",
    " easier. However, we will definitely want to see each of the column names so that we know what kinds of data are available to us.\n",
    "  Try pulling out all of the column names."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "IbduZJmkFbha",
    "colab": {}
   },
   "source": [
    "for col in df.columns:\n",
    "    print(col)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UaaweiK-Fbhe"
   },
   "source": [
    "**Question:**<br>\n",
    "What are the data types in each column?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "IdltHuv2Fbhe",
    "scrolled": true,
    "colab": {}
   },
   "source": [
    "print(df.dtypes)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eTNbnBtPFbhk"
   },
   "source": [
    "One of the inevitable frustrations in working with large datasets is that they can be messy. Often, values can be missing.\n",
    "Values might be missing because they don't apply, or simply because they got lost in the shuffle\n",
    " (e.g. wasn't recorded, data was corrupted, etc.)\n",
    " Missing values can take different forms in different datasets -\n",
    "  and sometimes even multiple forms!\n",
    "  One typical form is NaN, which is an acronym for Not A Number. <br><br>\n",
    "**Question:**<br>\n",
    "How many NaN's appear in each column? How many total across columns?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "A2slm7OHFbhm",
    "colab": {}
   },
   "source": [
    "print(\"Nans in columns\", df.isna().sum())\n",
    "print(\"Nans in rows\", df.isnull().sum(axis=1))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rMSMEQE0Fbhp"
   },
   "source": [
    "**Exercise:**<br>\n",
    "Let's take a look at all the columns that pertain to the amounts of money each company has\n",
    "raised. How many columns are relevant? Can you pull them all out at once?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "HIPIwfl0Fbhq",
    "scrolled": true,
    "colab": {}
   },
   "source": [
    "for col in df.columns:\n",
    "    if 'raise' in col:\n",
    "        print(col)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "txuuFZLMFbht"
   },
   "source": [
    "\n",
    "One of the first things that you should notice is that the column 'raised_amount_each' is\n",
    "completely useless. This kind of thing is another unfortunate consequence of large datasets -\n",
    "they can be messy, and sometimes data doesn't get filled in correctly.\n",
    "\n",
    "Luckily, there is another column that can help us out here.\n",
    "Let's take a look at 'raised_amount_total_usd'.\n",
    "\n",
    "You've probably noticed that some rows contain numbers, while others contain NaN's.\n",
    "\n",
    "**Question:**<br>\n",
    "How many rows contain numbers?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "pCqR3C4uFbhu",
    "scrolled": true,
    "colab": {}
   },
   "source": [
    "print( len(df['raised_amount_total_usd'])-df['raised_amount_total_usd'].isna().sum())\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MR93DbFgFbhx"
   },
   "source": [
    "**Question:**<br>\n",
    "How much money in total was raised across every company in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "FMIEZsk3Fbhz",
    "scrolled": true,
    "colab": {}
   },
   "source": [
    "print(df['raised_amount_total_usd'].sum())\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YZ-_kvf_Fbh3"
   },
   "source": [
    "Did you get an error? Oh noooooo! Can you piece together what happened from the TypeError?\n",
    "What type of data appears in that column? What can you do to remedy it?\n",
    "\n",
    "(*Hint: you'll need to convert these values, but this may be a 2-step process.\n",
    " You may need to remove certain elements first.*)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "eSBheM0WFbh5",
    "colab": {}
   },
   "source": [
    "df_new = df.dropna(subset=['raised_amount_total_usd'])\n",
    "df_new['raised_amount_total_usd']=df_new['raised_amount_total_usd'].astype(str).str.strip()\n",
    "df_new['raised_amount_total_usd'] = df_new['raised_amount_total_usd'].str.replace(',','')\n",
    "df_new = df_new[~df_new['raised_amount_total_usd'].str.contains(\"-\")]\n",
    "df_new['raised_amount_total_usd'] = df_new['raised_amount_total_usd'].astype(float)\n"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chiara/PycharmProjects/PandasTraining/venv/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/chiara/PycharmProjects/PandasTraining/venv/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ymXIuVRTFbiA"
   },
   "source": [
    "Ok, whew! Now that THAT'S done, we can return to our question.\n",
    "\n",
    "**Question:**<br>\n",
    "How much money in total was raised across every company in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "m-0zlLeLFbiC",
    "colab": {}
   },
   "source": [
    "print(df_new['raised_amount_total_usd'].sum())\n",
    "\n"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280964574193.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ULh6LgubFbiK"
   },
   "source": [
    "WOW! That's a lot of moola!! Does it make you want to start a business??\n",
    "Let's pretend you said 'yes'. And, since you're no dummy,\n",
    "I'm sure you would do the appropriate market research before crafting a business model.\n",
    "\n",
    "**Question**:<br>\n",
    "How many unique types of company markets are there? What are they?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "abBXnUOyFbiM",
    "colab": {}
   },
   "source": [
    "print(len(df_new['company_market'].unique()))\n",
    "\n",
    "print(df_new['company_market'].unique())\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JgBdjFaIFbiU"
   },
   "source": [
    "As I'm sure you've guessed, not all of these markets received an equal share of investment\n",
    "money. Let's try breaking investment down by different markets!\n",
    "\n",
    "**Question:**<br>\n",
    "How much money was invested in each company market?\n",
    "\n",
    "(*Hint: You'll need to **group** the data **by** market type...*)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cO-jFacjNffP",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "print(df_new.groupby('company_market')['raised_amount_total_usd'].sum())\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8nAO0kKNffR",
    "colab_type": "text"
   },
   "source": [
    "It's good to know how much investment each market saw,\n",
    "but we need a bit more organization here.\n",
    "We don't want to build our startup in just ANY market, we want the HOTTEST market!\n",
    "\n",
    "**Question:**<br>\n",
    "Which company markets received the most investment money? Find the top 10."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "nCgsvj2kFbiV",
    "colab": {}
   },
   "source": [
    "print(df_new.groupby('company_market')['raised_amount_total_usd'].sum().nlargest(10))\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lpLIlLWWFbic"
   },
   "source": [
    "**Question:**<br>\n",
    "Which company markets received no investment money?\n",
    "Can you find the bottom 3 markets to recieve at least SOME investment money (aka more than $0)?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "QAT5iKHuFbig",
    "colab": {}
   },
   "source": [
    "grouped = df_new.groupby('company_market')['raised_amount_total_usd'].sum()\n",
    "print(grouped[grouped==0])\n",
    "print(grouped.nsmallest(3))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCvs42GUSmsV",
    "colab_type": "text"
   },
   "source": [
    "Fantastic work! Now we know which company markets to avoid, and which to pursue. \n",
    "\n",
    "Next, we will want to narrow down WHERE to build our startup.\n",
    "After all, funding can change based on where our business is located!\n",
    "\n",
    "**Question:**<br>\n",
    "In which countries did startups in the top market recieve the most funding?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SB32r4dvNffY",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "largest_10 = df_new.groupby('company_market')['raised_amount_total_usd'].sum().nlargest(10).index\n",
    "print(df_new[df_new['company_market'].isin(largest_10)].groupby('company_country_code')['raised_amount_total_usd'].sum().sort_values(ascending=False))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4Q-ALMHNffa",
    "colab_type": "text"
   },
   "source": [
    "Woohoo! Go USA! But should we start our business in Maine?\n",
    "In Florida? In Washington state? Let's try narrowing it down even further.\n",
    "\n",
    "**Question:**<br>\n",
    "Which state of the top country in the top company market recieved the most investment funding?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UuHTXe-aNffa",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "top_countries = df_new[df_new['company_market'].isin(largest_10)].groupby('company_country_code')['raised_amount_total_usd'].sum().sort_values(ascending=False)\n",
    "top_country = top_countries.index[0]\n",
    "print(top_country)\n",
    "print(df_new[(df_new['company_market'].isin(largest_10)) & (df_new['company_country_code'] == top_country)].groupby('company_state_code')['raised_amount_total_usd'].sum().nlargest(1))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbTPT0dtNffc",
    "colab_type": "text"
   },
   "source": [
    "Great! Now let's zoom in even further! \n",
    "\n",
    "**Quesiton:**<br>\n",
    "How about the cities in the top state?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ylcqaiysNffc",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "top_states = df_new[(df_new['company_market'].isin(largest_10)) & (df_new['company_country_code'] == top_country)].groupby('company_state_code')['raised_amount_total_usd'].sum().nlargest(1).index\n",
    "print(top_states[0])\n",
    "print(df_new[(df_new['company_market'].isin(largest_10)) & (df_new['company_country_code'] == top_country) & (df_new['company_state_code'] == top_states[0])].groupby('company_city')['raised_amount_total_usd'].sum().sort_values(ascending=False))\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bS0jq5zQNffe",
    "colab_type": "text"
   },
   "source": [
    "Are you surprised by the city? It turns out that our cofounder, Investra Q. McMoney, **hates**\n",
    "the hot weather. But maybe there are other cities that would be good candidates for our startup...\n",
    "\n",
    "**Question:**<br>\n",
    "What are the top 5 cities in the USA for biotechnology company market investment funding?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "id": "XPm0BWCfNffe",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "print(df_new[(df_new['company_market']=='Biotechnology') & (df_new['company_country_code'] == top_country)].groupby('company_city')['raised_amount_total_usd'].sum().nlargest(5))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-SbfrjNNffh",
    "colab_type": "text"
   },
   "source": [
    "Fantastic! Looks like we have at least a few locations to scout!\n",
    "\n",
    "In the meantime, we should consider the sources of funding. With that in mind,\n",
    "let's turn our attention to investor markets.\n",
    "\n",
    "**Question:**<br>\n",
    "Which investor markets raised the most money?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "id": "tCEmnhHcNffh",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "print(df_new.groupby('investor_market')['raised_amount_total_usd'].sum().sort_values(ascending=False))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBoSsworNffj",
    "colab_type": "text"
   },
   "source": [
    "Are you surprised? How do you interpret the difference between company market\n",
    " investment and investment market investment?\n",
    " Why wouldn't these numbers be the same? Interpreting these types of apparent mis-matches is\n",
    "  super important, especially when it comes to generating actionable insights.\n",
    "\n",
    "But we should go deeper here. Let's look at this data over time, shall we?\n",
    "\n",
    "**Question:**<br>\n",
    "What is the earliest year for which we have funding data?\n",
    "What is the latest year?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BE5f-mb5Nffj",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "print(df_new['funded_year'].min())\n",
    "print(df_new['funded_year'].max())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCXz0EX3Nffl",
    "colab_type": "text"
   },
   "source": [
    "Let's take a look at how the investor market has changed over time.\n",
    "We don't want to get ourselves ensnared in a bubble!\n",
    "\n",
    "**Question:**<br>\n",
    "What investor market raised the most money in the earliest year for which we have data?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "id": "pOOgNhu8Nffl",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "df_new = df_new.dropna(subset = ['investor_market'])\n",
    "earliest = df_new['funded_year'].min()\n",
    "print(earliest)\n",
    "print(df_new[df_new['funded_year'] == earliest].groupby('investor_market')['raised_amount_total_usd'].sum().nlargest(1))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UuPa5ksFNffn",
    "colab_type": "text"
   },
   "source": [
    "Did you get any results? Wny not? Try to troubleshoot.\n",
    "\n",
    "This is another problem with big datasets. Sometimes they can be sparser than they appear.\n",
    "\n",
    "Any one particular year, especially earlier years in this dataset,\n",
    " may not have much representation in this dataset.\n",
    " One way to approach this problem, then, is to look at investor markets using larger\n",
    " temporal windows.\n",
    "\n",
    "**Exercise:**\n",
    "Look at money raised in different investor markets over larger windows of time.\n",
    "How have the investor markets changed over time? What used to be hot? Whats hot now?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CaEUn59HNffn",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#df_time = df_new.set_index('funded_year')\n",
    "df_new['funded_year'] = pd.to_datetime(df_new.funded_year, format='%Y')\n",
    "print(df_new.groupby([pd.Grouper(key=\"funded_year\", freq=\"5Y\"), 'investor_market'])['raised_amount_total_usd'].sum().reset_index().sort_values(['funded_year','raised_amount_total_usd']))\n"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    funded_year        investor_market  raised_amount_total_usd\n",
      "0    1989-12-31        Venture Capital             2.500000e+06\n",
      "2    1994-12-31                Finance             3.400000e+05\n",
      "3    1994-12-31    Hardware + Software             1.300000e+07\n",
      "1    1994-12-31              Education             1.755000e+07\n",
      "4    1994-12-31                  Legal             1.755000e+07\n",
      "..          ...                    ...                      ...\n",
      "293  2014-12-31            Health Care             9.574701e+09\n",
      "406  2014-12-31               Software             1.149453e+10\n",
      "314  2014-12-31  Investment Management             2.721440e+10\n",
      "283  2014-12-31                Finance             6.690651e+10\n",
      "429  2014-12-31        Venture Capital             7.401890e+10\n",
      "\n",
      "[443 rows x 3 columns]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8bqGkM3Nffp",
    "colab_type": "text"
   },
   "source": [
    "Looks like some investor markets have changed,\n",
    "but others are very consistent!\n",
    "\n",
    "**Exercise:**<br>\n",
    "How does the investor market compare to company markets\n",
    "for these same windows of time?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "emvzAXhCNffq",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "print(df_new.groupby([pd.Grouper(key=\"funded_year\", freq=\"5Y\"), 'company_market'])['raised_amount_total_usd'].sum().reset_index().sort_values(['funded_year','raised_amount_total_usd']))\n"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     funded_year       company_market  raised_amount_total_usd\n",
      "0     1979-12-31  Enterprise Software             2.000000e+06\n",
      "1     1989-12-31             Software             2.500000e+06\n",
      "4     1994-12-31                Games             6.000000e+04\n",
      "3     1994-12-31           Consulting             3.350000e+06\n",
      "5     1994-12-31             Software             4.134000e+07\n",
      "...          ...                  ...                      ...\n",
      "868   2014-12-31          Health Care             3.706816e+10\n",
      "678   2014-12-31     Clean Technology             3.960144e+10\n",
      "775   2014-12-31           E-Commerce             4.242423e+10\n",
      "1168  2014-12-31             Software             4.482451e+10\n",
      "645   2014-12-31        Biotechnology             9.838299e+10\n",
      "\n",
      "[1273 rows x 3 columns]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5mw8S4xNffr",
    "colab_type": "text"
   },
   "source": [
    "Congratulations, smarties!\n",
    "You've made it to the end of this introduction to Pandas!\n",
    "\n",
    "But this is really only where exploratory data analysis begins. The next step in EDA is data visualization. Try to come up with different data visualizations for these data. Data viz can often shed light on some surprising aspects of your data, and can inspire whole new analyses that you might not have otherwise expected.\n",
    "\n",
    "\n",
    "Here are some ideas for data stories you can tell using visualizatitons:<br>\n",
    "* Try plotting a time series of funding by company or investor market. \n",
    "* Which industries are receiving the most funding?<br> \n",
    "* Are there differences in the funding structures of different industries?<br>\n",
    "* What is the geographical distribution of funding?<br>\n",
    "* How has startup funding changed over time?<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "syFWWnd8Nffs",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Tv6m7qKNfft",
    "colab_type": "text"
   },
   "source": [
    "But EDA is really only the jumping off point for real Data Science. The bread and butter of DS is data analysis, to which none of you are strangers. Try your hand at some analysis! Begin by importing some additional libraries. What kind of machine learning algorithms can you apply? Think carefully about why you would user one ML technique over another. This is a critical skill: companies will care about how you think about data. Your advanced degree is a big leg-up here: you've had experience thinking deeply about complex problems and the appropriaite analyses to apply to them. What can you come up with?\n",
    "\n",
    "\n",
    "Here are some ideas of analyses or avenues of investigation:\n",
    "* How does early round funding impact the future success of a company?\n",
    "* Does goegraphical location affect the funding or future success of a company?\n",
    "* How significant are the results?\n",
    "* Does it qualitatively make sense?\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "q2iFhnJ-Nffu",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2D24Vl8Nffv",
    "colab_type": "text"
   },
   "source": [
    "Discuss these topics with your fellow Fellows on the Platform:\n",
    "* Why are your results interesting?\n",
    "* Could you imagine a useful product on top of this?\n",
    "* From a technical point-of-view, what was challenging about dealing with this dataset?\n",
    "* What were the hardest points or roadblocks along the way?\n",
    "* Are there any secondary data sources you can call upon to gain further insight?\n",
    "* Where did you make wrong turns?\n",
    "* What aspects of analysis did you get stuck on?\n",
    "* How would you approach your workflow differently?\n",
    "* Could task sharing or communication be streamlined?\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UQDImWafNffv",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}