{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Pandas.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-4gr26tJFbg6"
   },
   "source": [
    "# Pandas and Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nG1qwwpVFbg8"
   },
   "source": [
    "It's important that you hone your Pandas and exploratory data analysis (EDA) skills before the session starts. If you are having trouble, Google is your best friend! If you are still having problems, ask your fellow Fellows for help through the Platform. Good luck!\n",
    "<br> <br>\n",
    "Begin by downloading the Crunchbase dataset on start-up investments, which can be found [here](https://drive.google.com/file/d/1zsjN1tGWdXPb4wf4eTM62usMciSV-0sX/view)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GwK-b_KMFbg9"
   },
   "source": [
    "**Exercise:**\n",
    "The first thing we should do is import the Pandas library. It will probably be helpful to give this library an alias, too. Then, import the dataset and give it a name!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "1mXvrnK2Fbg_",
    "scrolled": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 494
    },
    "outputId": "fde579a2-ac5c-4ce8-9b1d-2ee8248d0158"
   },
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./Crunchbase_Startup_Investment_Data.csv\")"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xf3 in position 7: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnicodeDecodeError\u001B[0m                        Traceback (most recent call last)",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._string_convert\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers._string_box_utf8\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mUnicodeDecodeError\u001B[0m: 'utf-8' codec can't decode byte 0xf3 in position 7: invalid continuation byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mUnicodeDecodeError\u001B[0m                        Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-3fb31beb5ac0>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"./Crunchbase_Startup_Investment_Data.csv\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/PandasTraining/venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001B[0m\n\u001B[1;32m    684\u001B[0m     )\n\u001B[1;32m    685\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 686\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    687\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    688\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/PandasTraining/venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    456\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    457\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 458\u001B[0;31m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mparser\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnrows\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    459\u001B[0m     \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    460\u001B[0m         \u001B[0mparser\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/PandasTraining/venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36mread\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m   1184\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnrows\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1185\u001B[0m         \u001B[0mnrows\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_validate_integer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"nrows\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnrows\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1186\u001B[0;31m         \u001B[0mret\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnrows\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1187\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1188\u001B[0m         \u001B[0;31m# May alter columns / col_dict\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/PandasTraining/venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36mread\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m   2143\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnrows\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2144\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2145\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reader\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnrows\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2146\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mStopIteration\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2147\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_first_chunk\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader.read\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._read_rows\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._string_convert\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers._string_box_utf8\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mUnicodeDecodeError\u001B[0m: 'utf-8' codec can't decode byte 0xf3 in position 7: invalid continuation byte"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6TFhcHVVFbhI"
   },
   "source": [
    "Some of you may have experienced a problem already - thats ok! We can deal.\n",
    "<br><br>\n",
    "The problem here is that the dataset is encoded in Latin-1, but Pandas has defaulted to UTF-8 encoding. Bad, pandas! But it's ok, you can correct for this by specifying the encoding in your command. <br><br>\n",
    "*Pro tip:* If you're having trouble, try Googling your error messages. You are probably not the first to encounter any particular error."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "kXmLvm0gFbhJ",
    "colab": {}
   },
   "source": [
    "df = pd.read_csv(\"./Crunchbase_Startup_Investment_Data.csv\", encoding='latin1')\n",
    "\n"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cAh6GX0DFbhM"
   },
   "source": [
    "Now that we have successfully imported the data, let's do some Exploratory Data Analysis! \n",
    "\n",
    "**Exercise:**<br>\n",
    "Let's begin by displaying the first 5 rows of each column. <br>(*Hint: there is a special command for this!*)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "1NyRT2qCFbhO",
    "colab": {}
   },
   "source": [
    "print(df.head())\n"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     company_permalink           company_name  \\\n",
      "0  /organization/andrewburnett-com-ltd  AndrewBurnett.com Ltd   \n",
      "1               /organization/abo-data               ABO Data   \n",
      "2               /organization/abo-data               ABO Data   \n",
      "3                   /organization/ikro                   Ikro   \n",
      "4               /organization/indelsul               Indelsul   \n",
      "\n",
      "                               company_category_list       company_market  \\\n",
      "0  |Internet|SEO|Services|Public Relations|Social...             Internet   \n",
      "1                              |Enterprise Software|  Enterprise Software   \n",
      "2                              |Enterprise Software|  Enterprise Software   \n",
      "3                                                NaN                  NaN   \n",
      "4                                                NaN                  NaN   \n",
      "\n",
      "  company_country_code company_state_code company_region company_city  \\\n",
      "0                  GBR                NaN      Edinburgh    Edinburgh   \n",
      "1                  USA                 TX     TX - Other        Italy   \n",
      "2                  USA                 TX     TX - Other        Italy   \n",
      "3                  BRA                NaN    BRA - Other       Canoas   \n",
      "4                  NaN                NaN            NaN          NaN   \n",
      "\n",
      "                             investor_permalink  \\\n",
      "0                            /organization/ekaf   \n",
      "1                       /person/antonio-murroni   \n",
      "2                       /person/filippo-murroni   \n",
      "3  /organization/crp-companhia-de-participacoes   \n",
      "4  /organization/crp-companhia-de-participacoes   \n",
      "\n",
      "                      investor_name  ... investor_city  \\\n",
      "0                              Ekaf  ...           NaN   \n",
      "1                   ANTONIO MURRONI  ...           NaN   \n",
      "2                   FILIPPO Murroni  ...           NaN   \n",
      "3  CRP Companhia de Participac?o?es  ...           NaN   \n",
      "4  CRP Companhia de Participac?o?es  ...           NaN   \n",
      "\n",
      "                           funding_round_permalink funding_round_type  \\\n",
      "0  /funding-round/14fe2864e02d0f15ddc3ec8eacdc8e1b               seed   \n",
      "1  /funding-round/809e211b969c3f66440fc15ffcd29385               seed   \n",
      "2  /funding-round/809e211b969c3f66440fc15ffcd29385               seed   \n",
      "3  /funding-round/46c353a8249170cc4b6ab89a522fefdc            venture   \n",
      "4  /funding-round/48e8db0d90f95934831603622cb3f46a            venture   \n",
      "\n",
      "  funding_round_code   funded_at funded_month funded_quarter funded_year  \\\n",
      "0                NaN  1974-01-01      1974-01        1974-Q1        1974   \n",
      "1                NaN  1979-01-01      1979-01        1979-Q1        1979   \n",
      "2                NaN  1979-01-01      1979-01        1979-Q1        1979   \n",
      "3                  A  1982-06-01      1982-06        1982-Q2        1982   \n",
      "4                  A  1982-12-01      1982-12        1982-Q4        1982   \n",
      "\n",
      "  raised_amount_total_usd raised_amount_each  \n",
      "0                     NaN               -     \n",
      "1              1,000,000             #DIV/0!  \n",
      "2              1,000,000             #DIV/0!  \n",
      "3                724,000             #DIV/0!  \n",
      "4                165,000             #DIV/0!  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8CzgyRDxFbhT"
   },
   "source": [
    "**Question:**<br>\n",
    "How many columns are in this dataset? How many rows?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "laPNW9a5FbhU",
    "colab": {}
   },
   "source": [
    "print(\"N of rows\", len(df))\n",
    "print(\"N of columns\", len(df.columns))\n",
    "print(df.info())"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N of rows 114505\n",
      "N of columns 25\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 114505 entries, 0 to 114504\n",
      "Data columns (total 25 columns):\n",
      " #   Column                   Non-Null Count   Dtype \n",
      "---  ------                   --------------   ----- \n",
      " 0   company_permalink        114505 non-null  object\n",
      " 1   company_name             114504 non-null  object\n",
      " 2   company_category_list    111242 non-null  object\n",
      " 3   company_market           111240 non-null  object\n",
      " 4   company_country_code     107146 non-null  object\n",
      " 5   company_state_code       79158 non-null   object\n",
      " 6   company_region           107146 non-null  object\n",
      " 7   company_city             105800 non-null  object\n",
      " 8   investor_permalink       114439 non-null  object\n",
      " 9   investor_name            114439 non-null  object\n",
      " 10  investor_category_list   30507 non-null   object\n",
      " 11  investor_market          30455 non-null   object\n",
      " 12  investor_country_code    86521 non-null   object\n",
      " 13  investor_state_code      62274 non-null   object\n",
      " 14  investor_region          86521 non-null   object\n",
      " 15  investor_city            86007 non-null   object\n",
      " 16  funding_round_permalink  114505 non-null  object\n",
      " 17  funding_round_type       114505 non-null  object\n",
      " 18  funding_round_code       54669 non-null   object\n",
      " 19  funded_at                114505 non-null  object\n",
      " 20  funded_month             114505 non-null  object\n",
      " 21  funded_quarter           114505 non-null  object\n",
      " 22  funded_year              114505 non-null  int64 \n",
      " 23  raised_amount_total_usd  101154 non-null  object\n",
      " 24  raised_amount_each       114505 non-null  object\n",
      "dtypes: int64(1), object(24)\n",
      "memory usage: 21.8+ MB\n",
      "None\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WZSTCh8WFbhZ"
   },
   "source": [
    "**Exercise:**<br>\n",
    "You'll probably notice that the command above actually truncates the number of columns it shows. This is to make display\n",
    " easier. However, we will definitely want to see each of the column names so that we know what kinds of data are available to us.\n",
    "  Try pulling out all of the column names."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "IbduZJmkFbha",
    "colab": {}
   },
   "source": [
    "for col in df.columns:\n",
    "    print(col)"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company_permalink\n",
      "company_name\n",
      "company_category_list\n",
      "company_market\n",
      "company_country_code\n",
      "company_state_code\n",
      "company_region\n",
      "company_city\n",
      "investor_permalink\n",
      "investor_name\n",
      "investor_category_list\n",
      "investor_market\n",
      "investor_country_code\n",
      "investor_state_code\n",
      "investor_region\n",
      "investor_city\n",
      "funding_round_permalink\n",
      "funding_round_type\n",
      "funding_round_code\n",
      "funded_at\n",
      "funded_month\n",
      "funded_quarter\n",
      "funded_year\n",
      "raised_amount_total_usd\n",
      "raised_amount_each\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UaaweiK-Fbhe"
   },
   "source": [
    "**Question:**<br>\n",
    "What are the data types in each column?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "IdltHuv2Fbhe",
    "scrolled": true,
    "colab": {}
   },
   "source": [
    "print(df.dtypes)\n"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company_permalink          object\n",
      "company_name               object\n",
      "company_category_list      object\n",
      "company_market             object\n",
      "company_country_code       object\n",
      "company_state_code         object\n",
      "company_region             object\n",
      "company_city               object\n",
      "investor_permalink         object\n",
      "investor_name              object\n",
      "investor_category_list     object\n",
      "investor_market            object\n",
      "investor_country_code      object\n",
      "investor_state_code        object\n",
      "investor_region            object\n",
      "investor_city              object\n",
      "funding_round_permalink    object\n",
      "funding_round_type         object\n",
      "funding_round_code         object\n",
      "funded_at                  object\n",
      "funded_month               object\n",
      "funded_quarter             object\n",
      "funded_year                 int64\n",
      "raised_amount_total_usd    object\n",
      "raised_amount_each         object\n",
      "dtype: object\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eTNbnBtPFbhk"
   },
   "source": [
    "One of the inevitable frustrations in working with large datasets is that they can be messy. Often, values can be missing.\n",
    "Values might be missing because they don't apply, or simply because they got lost in the shuffle\n",
    " (e.g. wasn't recorded, data was corrupted, etc.)\n",
    " Missing values can take different forms in different datasets -\n",
    "  and sometimes even multiple forms!\n",
    "  One typical form is NaN, which is an acronym for Not A Number. <br><br>\n",
    "**Question:**<br>\n",
    "How many NaN's appear in each column? How many total across columns?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "A2slm7OHFbhm",
    "colab": {}
   },
   "source": [
    "print(\"Nans in columns\", df.isna().sum())\n",
    "print(\"Nans in rows\", df.isnull().sum(axis=1))"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nans in columns company_permalink              0\n",
      "company_name                   1\n",
      "company_category_list       3263\n",
      "company_market              3265\n",
      "company_country_code        7359\n",
      "company_state_code         35347\n",
      "company_region              7359\n",
      "company_city                8705\n",
      "investor_permalink            66\n",
      "investor_name                 66\n",
      "investor_category_list     83998\n",
      "investor_market            84050\n",
      "investor_country_code      27984\n",
      "investor_state_code        52231\n",
      "investor_region            27984\n",
      "investor_city              28498\n",
      "funding_round_permalink        0\n",
      "funding_round_type             0\n",
      "funding_round_code         59836\n",
      "funded_at                      0\n",
      "funded_month                   0\n",
      "funded_quarter                 0\n",
      "funded_year                    0\n",
      "raised_amount_total_usd    13351\n",
      "raised_amount_each             0\n",
      "dtype: int64\n",
      "Nans in rows 0          9\n",
      "1          7\n",
      "2          7\n",
      "3          9\n",
      "4         12\n",
      "          ..\n",
      "114500     2\n",
      "114501     9\n",
      "114502     6\n",
      "114503     6\n",
      "114504     8\n",
      "Length: 114505, dtype: int64\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rMSMEQE0Fbhp"
   },
   "source": [
    "**Exercise:**<br>\n",
    "Let's take a look at all the columns that pertain to the amounts of money each company has\n",
    "raised. How many columns are relevant? Can you pull them all out at once?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "HIPIwfl0Fbhq",
    "scrolled": true,
    "colab": {}
   },
   "source": [
    "for col in df.columns:\n",
    "    if 'raise' in col:\n",
    "        print(col)"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raised_amount_total_usd\n",
      "raised_amount_each\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "txuuFZLMFbht"
   },
   "source": [
    "\n",
    "One of the first things that you should notice is that the column 'raised_amount_each' is\n",
    "completely useless. This kind of thing is another unfortunate consequence of large datasets -\n",
    "they can be messy, and sometimes data doesn't get filled in correctly.\n",
    "\n",
    "Luckily, there is another column that can help us out here.\n",
    "Let's take a look at 'raised_amount_total_usd'.\n",
    "\n",
    "You've probably noticed that some rows contain numbers, while others contain NaN's.\n",
    "\n",
    "**Question:**<br>\n",
    "How many rows contain numbers?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "pCqR3C4uFbhu",
    "scrolled": true,
    "colab": {}
   },
   "source": [
    "print( len(df['raised_amount_total_usd'])-df['raised_amount_total_usd'].isna().sum())\n",
    "\n"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101154\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MR93DbFgFbhx"
   },
   "source": [
    "**Question:**<br>\n",
    "How much money in total was raised across every company in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "FMIEZsk3Fbhz",
    "scrolled": true,
    "colab": {}
   },
   "source": [
    "print(df['raised_amount_total_usd'].sum())\n"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-11-3c15315c07c7>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'raised_amount_total_usd'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/PandasTraining/venv/lib/python3.7/site-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36mstat_func\u001B[0;34m(self, axis, skipna, level, numeric_only, min_count, **kwargs)\u001B[0m\n\u001B[1;32m  11417\u001B[0m             \u001B[0mskipna\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mskipna\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m  11418\u001B[0m             \u001B[0mnumeric_only\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnumeric_only\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m> 11419\u001B[0;31m             \u001B[0mmin_count\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmin_count\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m  11420\u001B[0m         )\n\u001B[1;32m  11421\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/PandasTraining/venv/lib/python3.7/site-packages/pandas/core/series.py\u001B[0m in \u001B[0;36m_reduce\u001B[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001B[0m\n\u001B[1;32m   4234\u001B[0m                 )\n\u001B[1;32m   4235\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0merrstate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mall\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"ignore\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 4236\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdelegate\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mskipna\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mskipna\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   4237\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4238\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_reindex_indexer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnew_index\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindexer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/PandasTraining/venv/lib/python3.7/site-packages/pandas/core/nanops.py\u001B[0m in \u001B[0;36m_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     69\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     70\u001B[0m                 \u001B[0;32mwith\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0merrstate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minvalid\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"ignore\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 71\u001B[0;31m                     \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     72\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mValueError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     73\u001B[0m                 \u001B[0;31m# we want to transform an object array\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/PandasTraining/venv/lib/python3.7/site-packages/pandas/core/nanops.py\u001B[0m in \u001B[0;36mnansum\u001B[0;34m(values, axis, skipna, min_count, mask)\u001B[0m\n\u001B[1;32m    507\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mis_timedelta64_dtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    508\u001B[0m         \u001B[0mdtype_sum\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat64\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 509\u001B[0;31m     \u001B[0mthe_sum\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvalues\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype_sum\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    510\u001B[0m     \u001B[0mthe_sum\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_maybe_null_out\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthe_sum\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalues\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmin_count\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmin_count\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    511\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/PandasTraining/venv/lib/python3.7/site-packages/numpy/core/_methods.py\u001B[0m in \u001B[0;36m_sum\u001B[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001B[0m\n\u001B[1;32m     45\u001B[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001B[1;32m     46\u001B[0m          initial=_NoValue, where=True):\n\u001B[0;32m---> 47\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mumr_sum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkeepdims\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minitial\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mwhere\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     48\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001B[0;31mTypeError\u001B[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YZ-_kvf_Fbh3"
   },
   "source": [
    "Did you get an error? Oh noooooo! Can you piece together what happened from the TypeError?\n",
    "What type of data appears in that column? What can you do to remedy it?\n",
    "\n",
    "(*Hint: you'll need to convert these values, but this may be a 2-step process.\n",
    " You may need to remove certain elements first.*)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "eSBheM0WFbh5",
    "colab": {}
   },
   "source": [
    "df_new = df.dropna(subset=['raised_amount_total_usd'])\n",
    "df_new['raised_amount_total_usd']=df_new['raised_amount_total_usd'].astype(str).str.strip()\n",
    "df_new['raised_amount_total_usd'] = df_new['raised_amount_total_usd'].str.replace(',','')\n",
    "df_new = df_new[~df_new['raised_amount_total_usd'].str.contains(\"-\")]\n",
    "df_new['raised_amount_total_usd'] = df_new['raised_amount_total_usd'].astype(float)\n"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chiara/PycharmProjects/PandasTraining/venv/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/chiara/PycharmProjects/PandasTraining/venv/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ymXIuVRTFbiA"
   },
   "source": [
    "Ok, whew! Now that THAT'S done, we can return to our question.\n",
    "\n",
    "**Question:**<br>\n",
    "How much money in total was raised across every company in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "m-0zlLeLFbiC",
    "colab": {}
   },
   "source": [
    "print(df_new['raised_amount_total_usd'].sum())\n",
    "\n"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280964574193.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ULh6LgubFbiK"
   },
   "source": [
    "WOW! That's a lot of moola!! Does it make you want to start a business??\n",
    "Let's pretend you said 'yes'. And, since you're no dummy,\n",
    "I'm sure you would do the appropriate market research before crafting a business model.\n",
    "\n",
    "**Question**:<br>\n",
    "How many unique types of company markets are there? What are they?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "abBXnUOyFbiM",
    "colab": {}
   },
   "source": [
    "print(len(df_new['company_market'].unique()))\n",
    "\n",
    "print(df_new['company_market'].unique())\n"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "696\n",
      "['Enterprise Software' nan 'Software' 'Games' 'Advertising' 'Consulting'\n",
      " 'Web Hosting' 'Photography' 'Consumer Goods' 'Security' 'VoIP' 'Finance'\n",
      " 'Media' 'Internet' 'Digital Media' 'Mobile' 'Telecommunications'\n",
      " 'Business Services' 'Curated Web' 'E-Commerce' 'Auctions'\n",
      " 'Hardware + Software' 'Search' 'Information Technology' 'Analytics'\n",
      " 'Web Design' 'Human Resources' 'Medical' 'Social Media'\n",
      " 'Health and Wellness' 'Recipes' 'Market Research' 'Biotechnology'\n",
      " 'Technology' 'Television' 'Services' 'Manufacturing' 'Payments'\n",
      " 'Consumer Electronics' 'Investment Management' 'Messaging' 'Retail'\n",
      " 'Shopping' 'Advertising Platforms' 'Education' 'Real Estate' 'Wireless'\n",
      " 'Music' 'Hotels' 'Medical Devices' 'Nonprofits'\n",
      " 'Digital Rights Management' 'Online Shopping' 'Travel'\n",
      " 'Information Services' 'Enterprises' 'Search Marketing' 'Health Care'\n",
      " 'Travel & Tourism' 'Cloud Computing' 'Transportation'\n",
      " 'Business Intelligence' 'Forums' 'Semiconductors' 'Internet Marketing'\n",
      " 'Financial Services' 'Big Data Analytics' 'News' 'Shipping'\n",
      " 'Online Video Advertising' 'Commodities' 'Web Tools' 'Physicians'\n",
      " 'Public Relations' 'Storage' 'Email' 'Computers' 'Medical Professionals'\n",
      " 'Nanotechnology' 'Pharmaceuticals' 'Databases' 'Sports' 'Electronics'\n",
      " 'Clean Technology' 'Sales and Marketing' 'PaaS' 'SaaS' 'Real Time'\n",
      " 'Networking' 'Automotive' 'Fashion' 'Data Security'\n",
      " 'Public Transportation' 'Web Development' 'Handmade' 'Creative'\n",
      " 'Open Source' 'Mobile Security' 'Innovation Engineering' 'Android'\n",
      " 'Cable' 'Mobile Games' 'Flash Storage' 'iPhone' 'Broadcasting'\n",
      " 'Trusted Networks' 'Video' 'Hospitals' 'Design' 'Personal Branding'\n",
      " 'Customer Service' 'Audio' 'SMS' 'Marketing Automation' 'Publishing'\n",
      " 'E-Commerce Platforms' 'Communities' 'Linux' 'Entertainment' 'Navigation'\n",
      " 'Batteries' 'Employment' 'Agriculture' 'Freelancers'\n",
      " 'Communications Hardware' 'Coupons' 'Network Security' 'Peer-to-Peer'\n",
      " 'Hospitality' 'SEO' 'Content' 'Virtualization' 'Optimization'\n",
      " 'Data Integration' 'Semantic Web' 'CRM' 'Reviews and Recommendations'\n",
      " 'Legal' 'Local' 'Cloud Data Services' 'Classifieds'\n",
      " 'Social Network Media' 'Personal Finance' 'Crowdsourcing'\n",
      " 'Unifed Communications' 'Privacy' 'Outsourcing' 'Chat' 'Social Search'\n",
      " 'Internet of Things' 'Aerospace' 'Mobile Devices' 'Displays' 'Graphics'\n",
      " 'IT Management' 'Collaboration' 'Therapeutics' 'Video Streaming'\n",
      " 'Visual Search' 'Video on Demand' 'Video Games' 'Portals' 'Data Centers'\n",
      " 'Fraud Detection' 'Identity Management' 'Contact Management' 'Hardware'\n",
      " 'Infrastructure' 'Mobile Payments' 'File Sharing' 'B2B' 'RFID'\n",
      " 'Local Advertising' 'Digital Signage' 'Lighting' 'Photo Editing' 'Energy'\n",
      " 'Cloud Security' 'MMO Games' 'Web CMS' 'Engineering Firms' 'Maps'\n",
      " 'Productivity Software' 'Cosmetics' 'Demographies'\n",
      " 'Customer Support Tools' 'Email Marketing' 'Genetic Testing'\n",
      " 'Browser Extensions' 'Test and Measurement' 'Point of Sale'\n",
      " 'Content Creators' 'Online Scheduling' 'Guides' 'Governments' 'Tracking'\n",
      " 'Testing' 'App Marketing' 'Marketplaces' 'Social Media Advertising'\n",
      " 'Online Dating' 'Credit' 'Brand Marketing' 'Virtual Workforces'\n",
      " 'Risk Management' 'Brokers' 'Diagnostics' 'Gps' 'Consumer Internet'\n",
      " 'Predictive Analytics' 'Document Management' 'Social Games' 'Big Data'\n",
      " 'Meeting Software' 'Life Sciences' 'Cloud Management' 'Photo Sharing'\n",
      " 'Facebook Applications' 'Ediscovery' 'Supply Chain Management'\n",
      " 'Personalization' 'Toys' 'Price Comparison' 'Celebrity'\n",
      " 'Direct Marketing' 'Restaurants' 'Trading' 'Simulation' 'Kinect'\n",
      " 'App Stores' 'Finance Technology' 'Service Providers' 'Career Management'\n",
      " 'Corporate Training' 'Colleges' 'iOS' 'Enterprise Search' 'M2M'\n",
      " 'Cyber Security' 'Web Browsers' 'Social Bookmarking' 'Politics'\n",
      " 'Construction' 'Startups' 'Clean Energy' 'Tech Field Support' 'Women'\n",
      " 'Mobile Software Tools' 'Identity' 'Chemicals' 'Events'\n",
      " 'Image Recognition' 'Social Business' 'Local Based Services' 'Banking'\n",
      " 'Film' 'Logistics' 'Blogging Platforms' 'Developer APIs'\n",
      " 'Data Visualization' 'Apps' 'Creative Industries' 'Consumers' 'Gambling'\n",
      " 'Virtual Worlds' 'Religion' 'Doctors' 'All Markets' 'Lead Generation'\n",
      " 'Surveys' 'Vacation Rentals' 'Speech Recognition' 'Usability'\n",
      " 'Local Businesses' 'Monetization' 'Mobile Analytics' 'World Domination'\n",
      " 'Location Based Services' 'Cloud Infrastructure' 'Enterprise 2.0'\n",
      " 'Neuroscience' 'Data Mining' 'Game' 'Business Development' 'Cyber'\n",
      " 'Game Mechanics' 'Online Gaming' 'Discounts' 'Energy Management'\n",
      " 'Opinions' 'Venture Capital' 'Advertising Exchanges' 'Artists Globally'\n",
      " 'Enterprise Resource Planning' 'Concerts' 'Mobile Enterprise' 'Mobility'\n",
      " 'Auto' 'Wind' 'Tea' 'Ticketing' 'Solar'\n",
      " 'Semiconductor Manufacturing Equipment' 'Task Management' 'iPad'\n",
      " 'Recruiting' 'Art' 'Elder Care' 'Semantic Search' 'Plumbers' 'Social CRM'\n",
      " 'Social Buying' 'Gift Card' 'Beauty' 'Farming'\n",
      " 'Health Care Information Technology' 'Mobile Commerce' 'Sales Automation'\n",
      " 'Loyalty Programs' 'Windows Phone 7' 'Content Discovery'\n",
      " 'Small and Medium Businesses' 'Content Delivery' 'Property Management'\n",
      " 'Non Profit' 'Artificial Intelligence' 'Archiving'\n",
      " 'Application Platforms' 'Coworking' 'Online Travel'\n",
      " 'Social Media Marketing' 'Presentations' 'Internet Radio Market'\n",
      " 'Twitter Applications' 'Promotional' 'Robotics' 'Cars' 'Psychology'\n",
      " 'Tutoring' 'Match-Making' 'Kids' 'NFC' 'Environmental Innovation'\n",
      " 'Rapidly Expanding' 'Teenagers' 'Mobile Advertising' 'Smart Grid'\n",
      " 'Billing' 'Entrepreneur' 'Google Apps' 'Ad Targeting'\n",
      " 'Mining Technologies' 'Subscription Businesses' 'Leisure'\n",
      " 'Project Management' 'Pets' 'Lead Management' 'Fitness' 'Organic Food'\n",
      " 'All Students' 'Homeland Security' 'Architecture' 'Charity' 'Insurance'\n",
      " 'Career Planning' 'Business Productivity' 'Commercial Solar' 'Licensing'\n",
      " 'Specialty Chemicals' 'Oil' 'Nutrition' 'Social Media Monitoring'\n",
      " 'Craigslist Killers' 'Journalism' 'Incentives' 'Virtual Goods' '3D'\n",
      " 'Translation' 'Home Decor' 'Green' 'Accounting' 'Renewable Energies'\n",
      " 'Weddings' 'QR Codes' 'Recycling' 'Retail Technology' 'Machine Learning'\n",
      " 'Lifestyle' 'Wealth Management' 'Mobile Video' 'Flash Sales' 'Utilities'\n",
      " 'Charter Schools' 'Staffing Firms' 'Communications Infrastructure'\n",
      " 'Dental' 'Fantasy Sports' 'Performance Marketing'\n",
      " 'Distributed Generation' 'SNS' 'Cooking' 'Contests'\n",
      " 'New Product Development' 'Shoes' 'Credit Cards' 'Stock Exchanges'\n",
      " 'Water' 'Energy Efficiency' 'Data Center Automation'\n",
      " 'Green Consumer Goods' 'Direct Sales' 'Flowers' 'Training'\n",
      " 'Mobile Health' 'Taxis' 'Online Auctions' 'Twin-Tip Skis'\n",
      " 'Application Performance Monitoring' 'Development Platforms'\n",
      " 'IT and Cybersecurity' 'P2P Money Transfer' 'Data Privacy'\n",
      " 'Mobile Shopping' 'Sponsorship' 'Social Opinion Platform' 'Mobile Social'\n",
      " 'High Schools' 'Personal Health' 'Professional Networking'\n",
      " 'Adventure Travel' 'Interest Graph' 'Group Buying'\n",
      " 'User Experience Design' 'Online Identity' 'Collaborative Consumption'\n",
      " 'Diabetes' 'Financial Exchanges' 'Skill Assessment' 'Sustainability'\n",
      " 'Language Learning' 'Electronic Health Records' 'Residential Solar'\n",
      " 'Embedded Hardware and Software' 'Algorithms' 'IaaS' 'Home & Garden'\n",
      " 'Internet Service Providers' 'Spas' 'Tablets' 'Developer Tools'\n",
      " 'Online Reservations' 'K-12 Education' 'Healthcare Services'\n",
      " 'Homeless Shelter' 'Visualization' 'Emerging Markets' 'Systems'\n",
      " 'Local Search' 'Lingerie' 'Natural Resources' 'Polling' 'DIY'\n",
      " 'Social Media Platforms' 'Proximity Internet' 'Online Rental'\n",
      " 'Outdoor Advertising' 'Enterprise Security' 'Space Travel' 'Sunglasses'\n",
      " 'Enterprise Application' 'Nightclubs' 'Law Enforcement' 'Organic'\n",
      " 'Tourism' 'Employer Benefits Programs' 'Enterprise Purchasing' 'Jewelry'\n",
      " 'Telephony' 'Domains' 'Social Commerce' 'Private Social Networking'\n",
      " 'Sensors' 'Music Services' 'Franchises' 'Home Automation'\n",
      " 'Product Development Services' 'Government Innovation'\n",
      " 'Industrial Energy Efficiency' 'Baby Boomers' 'Advice' 'Textbooks'\n",
      " 'Printing' 'Synchronization' 'Natural Language Processing'\n",
      " 'Human Resource Automation' 'Augmented Reality'\n",
      " 'Data Center Infrastructure' 'Moneymaking' 'Geospatial'\n",
      " 'Health and Insurance' 'MicroBlogging' 'Reputation'\n",
      " 'Internet Infrastructure' 'Gamification' 'Mac' 'Parenting'\n",
      " 'Offline Businesses' 'Governance' 'App Discovery' 'DOD/Military' 'WebOS'\n",
      " 'Heavy Industry' 'Social Media Management' 'Event Management'\n",
      " 'Corporate Wellness' 'Home Owners' 'Collectibles' 'Registrars'\n",
      " 'Information Security' 'Distribution' 'Water Purification' 'High Tech'\n",
      " 'Crowdfunding' 'Mobile Coupons' '3D Printing' 'Commercial Real Estate'\n",
      " 'Material Science' 'College Recruiting' 'Intellectual Property'\n",
      " 'Human Computer Interaction' 'Coffee' 'Intelligent Systems'\n",
      " 'Clean Technology IT' 'Infrastructure Builders'\n",
      " 'Deep Information Technology' 'Wholesale' 'Music Education'\n",
      " 'Vertical Search' 'Oil & Gas' 'Product Design' 'Outdoors' 'Bitcoin'\n",
      " 'Social Recruiting' 'University Students' 'Video Conferencing'\n",
      " 'Oil and Gas' 'Mobile Emergency&Health' 'In-Flight Entertainment'\n",
      " 'Educational Games' 'Mobile Infrastructure' 'Film Production'\n",
      " 'Humanitarian' 'Social Travel' 'English-Speaking' 'Product Search'\n",
      " 'iPod Touch' 'Postal and Courier Services' 'Specialty Foods'\n",
      " 'Internet TV' 'Freemium' 'Business Analytics' 'Remediation' 'Q&A'\n",
      " 'Soccer' 'Computer Vision' 'Teachers' 'Health Services Industry'\n",
      " 'Energy IT' 'FreetoPlay Gaming' 'Self Development' 'Corporate IT'\n",
      " 'Food Processing' 'Electrical Distribution' 'E-Books' 'Groceries'\n",
      " 'Social Innovation' 'Business Information Systems'\n",
      " 'Professional Services' 'Drones' 'Content Syndication' 'Incubators'\n",
      " 'Unmanned Air Systems' 'Defense' 'Video Chat' 'Public Safety' 'Babies'\n",
      " 'Face Recognition' 'Group SMS' 'Biometrics' 'Gift Registries' 'Eyewear'\n",
      " 'Video Editing' 'Universities' 'Motion Capture' 'Internet Technology'\n",
      " 'Hedge Funds' 'Families' 'EBooks' 'Service Industries' 'Office Space'\n",
      " 'Logistics Company' 'Comparison Shopping' 'Fleet Management'\n",
      " 'Rental Housing' 'Writers' 'Bioinformatics' 'Boating Industry' 'Bicycles'\n",
      " 'Indoor Positioning' 'Lifestyle Products' 'Knowledge Management'\n",
      " 'Transaction Processing' 'Bridging Online and Offline'\n",
      " 'Mass Customization' 'Enterprise Hardware' 'New Technologies'\n",
      " 'Google Glass' 'Casual Games' 'Intellectual Asset Management'\n",
      " 'Distributors' 'Electric Vehicles' 'Sporting Goods' 'Interface Design'\n",
      " 'Senior Citizens' 'Retirement' 'Home Renovation' 'Wine And Spirits'\n",
      " 'Virtual Currency' 'Timeshares' 'Certification Test'\n",
      " 'Advertising Networks' 'Sex' '3D Technology' 'Lifestyle Businesses'\n",
      " 'Funeral Industry' 'Quantified Self' 'mHealth' 'CAD' 'Carbon'\n",
      " 'B2B Express Delivery' 'Local Commerce' 'Industrial'\n",
      " 'Social + Mobile + Local' 'Video Processing' 'Shared Services'\n",
      " 'Cosmetic Surgery' 'Entertainment Industry' 'Recreation' 'Resorts'\n",
      " 'Exercise' 'Self Storage' 'Radical Breakthrough Startups'\n",
      " 'Social Television' 'Mechanical Solutions' 'Innovation Management'\n",
      " 'Real Estate Investors' 'Digital Entertainment' 'Minerals' 'Music Venues'\n",
      " 'Craft Beer' 'Bio-Pharm' 'Text Analytics' 'Animal Feed' 'Civil Engineers'\n",
      " 'Industrial Automation' 'Angels' 'Veterinary' 'PC Gaming' 'TV Production'\n",
      " 'Textiles' 'Golf Equipment' 'Comics' 'Consumer Behavior'\n",
      " 'Ventures for Good' 'Assisitive Technology' 'Clinical Trials'\n",
      " 'Call Center Automation' 'Alternative Medicine' 'Insurance Companies'\n",
      " 'Biomass Power Generation' 'Smart Building' 'China Internet'\n",
      " 'Musical Instruments' 'Social Fundraising' 'College Campuses' 'Designers'\n",
      " 'Cloud-Based Music' 'Email Newsletters' 'Interior Design' 'Young Adults'\n",
      " 'Parking' 'Motors' 'Musicians' 'Consumer Lending'\n",
      " 'General Public Worldwide' 'Software Compliance']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JgBdjFaIFbiU"
   },
   "source": [
    "As I'm sure you've guessed, not all of these markets received an equal share of investment\n",
    "money. Let's try breaking investment down by different markets!\n",
    "\n",
    "**Question:**<br>\n",
    "How much money was invested in each company market?\n",
    "\n",
    "(*Hint: You'll need to **group** the data **by** market type...*)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cO-jFacjNffP",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "print(df_new.groupby('company_market')['raised_amount_total_usd'].sum())\n",
    "\n"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company_market\n",
      "3D               276971502.0\n",
      "3D Printing      118268000.0\n",
      "3D Technology     36339754.0\n",
      "Accounting       648683276.0\n",
      "Ad Targeting     433154447.0\n",
      "                    ...     \n",
      "iOS              411825539.0\n",
      "iPad              82633655.0\n",
      "iPhone           525327381.0\n",
      "iPod Touch        29238000.0\n",
      "mHealth             470693.0\n",
      "Name: raised_amount_total_usd, Length: 695, dtype: float64\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8nAO0kKNffR",
    "colab_type": "text"
   },
   "source": [
    "It's good to know how much investment each market saw,\n",
    "but we need a bit more organization here.\n",
    "We don't want to build our startup in just ANY market, we want the HOTTEST market!\n",
    "\n",
    "**Question:**<br>\n",
    "Which company markets received the most investment money? Find the top 10."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "nCgsvj2kFbiV",
    "colab": {}
   },
   "source": [
    "print(df_new.groupby('company_market')['raised_amount_total_usd'].sum().nlargest(10))\n",
    "\n"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company_market\n",
      "Biotechnology          1.493952e+11\n",
      "Software               8.670155e+10\n",
      "Clean Technology       6.981941e+10\n",
      "Health Care            6.005040e+10\n",
      "E-Commerce             4.950532e+10\n",
      "Mobile                 4.221446e+10\n",
      "Enterprise Software    4.218186e+10\n",
      "Internet               3.778165e+10\n",
      "Advertising            3.453942e+10\n",
      "Semiconductors         3.405033e+10\n",
      "Name: raised_amount_total_usd, dtype: float64\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lpLIlLWWFbic"
   },
   "source": [
    "**Question:**<br>\n",
    "Which company markets received no investment money?\n",
    "Can you find the bottom 3 markets to recieve at least SOME investment money (aka more than $0)?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "QAT5iKHuFbig",
    "colab": {}
   },
   "source": [
    "grouped = df_new.groupby('company_market')['raised_amount_total_usd'].sum()\n",
    "print(grouped[grouped==0])\n",
    "print(grouped.nsmallest(3))"
   ],
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: raised_amount_total_usd, dtype: float64)\n",
      "company_market\n",
      "Direct Sales        18000.0\n",
      "Self Development    20000.0\n",
      "Home Owners         22000.0\n",
      "Name: raised_amount_total_usd, dtype: float64\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCvs42GUSmsV",
    "colab_type": "text"
   },
   "source": [
    "Fantastic work! Now we know which company markets to avoid, and which to pursue. \n",
    "\n",
    "Next, we will want to narrow down WHERE to build our startup.\n",
    "After all, funding can change based on where our business is located!\n",
    "\n",
    "**Question:**<br>\n",
    "In which countries did startups in the top market recieve the most funding?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SB32r4dvNffY",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "largest_10 = df_new.groupby('company_market')['raised_amount_total_usd'].sum().nlargest(10).index\n",
    "print(df_new[df_new['company_market'].isin(largest_10)].groupby('company_country_code')['raised_amount_total_usd'].sum().sort_values(ascending=False))"
   ],
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company_country_code\n",
      "USA    4.531787e+11\n",
      "GBR    2.375944e+10\n",
      "CHN    2.298488e+10\n",
      "CAN    1.334112e+10\n",
      "IND    9.592028e+09\n",
      "           ...     \n",
      "DZA    2.930160e+05\n",
      "LBN    2.265000e+05\n",
      "NPL    2.000000e+05\n",
      "SRB    1.353700e+05\n",
      "BHR    4.500000e+04\n",
      "Name: raised_amount_total_usd, Length: 78, dtype: float64\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4Q-ALMHNffa",
    "colab_type": "text"
   },
   "source": [
    "Woohoo! Go USA! But should we start our business in Maine?\n",
    "In Florida? In Washington state? Let's try narrowing it down even further.\n",
    "\n",
    "**Question:**<br>\n",
    "Which state of the top country in the top company market recieved the most investment funding?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UuHTXe-aNffa",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "top_countries = df_new[df_new['company_market'].isin(largest_10)].groupby('company_country_code')['raised_amount_total_usd'].sum().sort_values(ascending=False)\n",
    "top_country = top_countries.index[0]\n",
    "print(top_country)\n",
    "print(df_new[(df_new['company_market'].isin(largest_10)) & (df_new['company_country_code'] == top_country)].groupby('company_state_code')['raised_amount_total_usd'].sum().nlargest(1))\n"
   ],
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USA\n",
      "company_state_code\n",
      "CA    2.164305e+11\n",
      "Name: raised_amount_total_usd, dtype: float64\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbTPT0dtNffc",
    "colab_type": "text"
   },
   "source": [
    "Great! Now let's zoom in even further! \n",
    "\n",
    "**Quesiton:**<br>\n",
    "How about the cities in the top state?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ylcqaiysNffc",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "top_states = df_new[(df_new['company_market'].isin(largest_10)) & (df_new['company_country_code'] == top_country)].groupby('company_state_code')['raised_amount_total_usd'].sum().nlargest(1).index\n",
    "print(top_states[0])\n",
    "print(df_new[(df_new['company_market'].isin(largest_10)) & (df_new['company_country_code'] == top_country) & (df_new['company_state_code'] == top_states[0])].groupby('company_city')['raised_amount_total_usd'].sum().sort_values(ascending=False))\n",
    "\n"
   ],
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CA\n",
      "company_city\n",
      "San Francisco      3.661035e+10\n",
      "San Jose           1.912768e+10\n",
      "San Diego          1.448075e+10\n",
      "Palo Alto          1.429985e+10\n",
      "Redwood City       1.355489e+10\n",
      "                       ...     \n",
      "Pala               4.533900e+05\n",
      "East Palo Alto     2.400000e+05\n",
      "California City    2.000000e+05\n",
      "Corte Madera       1.500000e+05\n",
      "Santa Cruz         1.230000e+05\n",
      "Name: raised_amount_total_usd, Length: 136, dtype: float64\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bS0jq5zQNffe",
    "colab_type": "text"
   },
   "source": [
    "Are you surprised by the city? It turns out that our cofounder, Investra Q. McMoney, **hates**\n",
    "the hot weather. But maybe there are other cities that would be good candidates for our startup...\n",
    "\n",
    "**Question:**<br>\n",
    "What are the top 5 cities in the USA for biotechnology company market investment funding?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "id": "XPm0BWCfNffe",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "print(df_new[(df_new['company_market']=='Biotechnology') & (df_new['company_country_code'] == top_country)].groupby('company_city')['raised_amount_total_usd'].sum().nlargest(5))\n"
   ],
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company_city\n",
      "Cambridge              1.192541e+10\n",
      "San Diego              9.189710e+09\n",
      "South San Francisco    5.948113e+09\n",
      "San Francisco          5.211797e+09\n",
      "Menlo Park             5.063562e+09\n",
      "Name: raised_amount_total_usd, dtype: float64\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-SbfrjNNffh",
    "colab_type": "text"
   },
   "source": [
    "Fantastic! Looks like we have at least a few locations to scout!\n",
    "\n",
    "In the meantime, we should consider the sources of funding. With that in mind,\n",
    "let's turn our attention to investor markets.\n",
    "\n",
    "**Question:**<br>\n",
    "Which investor markets raised the most money?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "id": "tCEmnhHcNffh",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "print(df_new.groupby('investor_market')['raised_amount_total_usd'].sum().sort_values(ascending=False))\n"
   ],
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "investor_market\n",
      "Venture Capital          1.057116e+11\n",
      "Finance                  8.841049e+10\n",
      "Investment Management    3.523649e+10\n",
      "Software                 2.236290e+10\n",
      "Health Care              1.492058e+10\n",
      "                             ...     \n",
      "Social Innovation        1.120000e+05\n",
      "Kids                     1.000000e+05\n",
      "Mobility                 8.263500e+04\n",
      "CRM                      6.000000e+04\n",
      "Office Space             2.500000e+04\n",
      "Name: raised_amount_total_usd, Length: 259, dtype: float64\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBoSsworNffj",
    "colab_type": "text"
   },
   "source": [
    "Are you surprised? How do you interpret the difference between company market\n",
    " investment and investment market investment?\n",
    " Why wouldn't these numbers be the same? Interpreting these types of apparent mis-matches is\n",
    "  super important, especially when it comes to generating actionable insights.\n",
    "\n",
    "But we should go deeper here. Let's look at this data over time, shall we?\n",
    "\n",
    "**Question:**<br>\n",
    "What is the earliest year for which we have funding data?\n",
    "What is the latest year?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BE5f-mb5Nffj",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "print(df_new['funded_year'].min())\n",
    "print(df_new['funded_year'].max())"
   ],
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1979\n",
      "2014\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCXz0EX3Nffl",
    "colab_type": "text"
   },
   "source": [
    "Let's take a look at how the investor market has changed over time.\n",
    "We don't want to get ourselves ensnared in a bubble!\n",
    "\n",
    "**Question:**<br>\n",
    "What investor market raised the most money in the earliest year for which we have data?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "id": "pOOgNhu8Nffl",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "df_new = df_new.dropna(subset = ['investor_market'])\n",
    "earliest = df_new['funded_year'].min()\n",
    "print(earliest)\n",
    "print(df_new[df_new['funded_year'] == earliest].groupby('investor_market')['raised_amount_total_usd'].sum().nlargest(1))"
   ],
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1987\n",
      "investor_market\n",
      "Venture Capital    2500000.0\n",
      "Name: raised_amount_total_usd, dtype: float64\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UuPa5ksFNffn",
    "colab_type": "text"
   },
   "source": [
    "Did you get any results? Wny not? Try to troubleshoot.\n",
    "\n",
    "This is another problem with big datasets. Sometimes they can be sparser than they appear.\n",
    "\n",
    "Any one particular year, especially earlier years in this dataset,\n",
    " may not have much representation in this dataset.\n",
    " One way to approach this problem, then, is to look at investor markets using larger\n",
    " temporal windows.\n",
    "\n",
    "**Exercise:**\n",
    "Look at money raised in different investor markets over larger windows of time.\n",
    "How have the investor markets changed over time? What used to be hot? Whats hot now?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CaEUn59HNffn",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8bqGkM3Nffp",
    "colab_type": "text"
   },
   "source": [
    "Looks like some investor markets have changed, but others are very consistent!\n",
    "\n",
    "**Exercise:**<br>\n",
    "How does the investor market compare to company markets for these same windows of time?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "emvzAXhCNffq",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5mw8S4xNffr",
    "colab_type": "text"
   },
   "source": [
    "Congratulations, smarties! You've made it to the end of this introduction to Pandas!\n",
    "\n",
    "But this is really only where exploratory data analysis begins. The next step in EDA is data visualization. Try to come up with different data visualizations for these data. Data viz can often shed light on some surprising aspects of your data, and can inspire whole new analyses that you might not have otherwise expected.\n",
    "\n",
    "\n",
    "Here are some ideas for data stories you can tell using visualizatitons:<br>\n",
    "* Try plotting a time series of funding by company or investor market. \n",
    "* Which industries are receiving the most funding?<br> \n",
    "* Are there differences in the funding structures of different industries?<br>\n",
    "* What is the geographical distribution of funding?<br>\n",
    "* How has startup funding changed over time?<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "syFWWnd8Nffs",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Tv6m7qKNfft",
    "colab_type": "text"
   },
   "source": [
    "But EDA is really only the jumping off point for real Data Science. The bread and butter of DS is data analysis, to which none of you are strangers. Try your hand at some analysis! Begin by importing some additional libraries. What kind of machine learning algorithms can you apply? Think carefully about why you would user one ML technique over another. This is a critical skill: companies will care about how you think about data. Your advanced degree is a big leg-up here: you've had experience thinking deeply about complex problems and the appropriaite analyses to apply to them. What can you come up with?\n",
    "\n",
    "\n",
    "Here are some ideas of analyses or avenues of investigation:\n",
    "* How does early round funding impact the future success of a company?\n",
    "* Does goegraphical location affect the funding or future success of a company?\n",
    "* How significant are the results?\n",
    "* Does it qualitatively make sense?\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "q2iFhnJ-Nffu",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2D24Vl8Nffv",
    "colab_type": "text"
   },
   "source": [
    "Discuss these topics with your fellow Fellows on the Platform:\n",
    "* Why are your results interesting?\n",
    "* Could you imagine a useful product on top of this?\n",
    "* From a technical point-of-view, what was challenging about dealing with this dataset?\n",
    "* What were the hardest points or roadblocks along the way?\n",
    "* Are there any secondary data sources you can call upon to gain further insight?\n",
    "* Where did you make wrong turns?\n",
    "* What aspects of analysis did you get stuck on?\n",
    "* How would you approach your workflow differently?\n",
    "* Could task sharing or communication be streamlined?\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UQDImWafNffv",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}